{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shape: torch.Size([4, 2048, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Feature Extractor\n",
    "from pytorchvideo.models.hub import x3d_s\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pretrained x3d_s model\n",
    "model = x3d_s(pretrained=True).to(device)\n",
    "\n",
    "# Modify block 5 to include explicit global average pooling\n",
    "class FeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.backbone = torch.nn.Sequential(*model.blocks[:-1])  # Blocks 0-4\n",
    "        self.final_block = model.blocks[5].pool  # Block 5 (unchanged)\n",
    "        self.pool = nn.AdaptiveAvgPool3d((1, 1, 1))  # Define global average pooling layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f\"Input shape: {x.shape}\")  # Debug input shape\n",
    "        x = self.backbone(x)  # Pass through blocks 0-4\n",
    "        # print(f\"After backbone shape: {x.shape}\")  # Debug backbone output shape\n",
    "        x=self.final_block(x)\n",
    "        # print(f\"After final_block shape: {x.shape}\")  # Debug backbone output shape\n",
    "        x = self.pool(x)  # Pass through block 5 pooling\n",
    "        # print(f\"After pooling shape: {x.shape}\")  # Debug pooling output shape\n",
    "\n",
    "        x = torch.mean(x, dim=[-3, -2, -1], keepdim=True)  # Apply global average pooling\n",
    "        # print(f\"After global average pooling shape: {x.shape}\")  # Debug GAP output shape\n",
    "\n",
    "        return x\n",
    "\n",
    "# Initialize the feature extractor\n",
    "feature_extractor = FeatureExtractor(model)\n",
    "\n",
    "# Define feature extraction function\n",
    "def extract_features(segments, device, model=feature_extractor):\n",
    "    \"\"\"\n",
    "    Extract features from video segments using the modified model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Pretrained and modified model.\n",
    "        segments (list): List of video segments (tensors).\n",
    "        device (torch.device): Device for computation.\n",
    "\n",
    "    Returns:\n",
    "        list: List of feature tensors.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for segment in segments:\n",
    "            segment = segment.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "            feature = model(segment)  # Extract features\n",
    "            features.append(feature.squeeze(0).cpu())  # Remove batch dimension and move to CPU\n",
    "    return features\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Test with a dummy input\n",
    "    dummy_input = torch.randn(4, 3, 16, 240, 320).to(device)  # Example input: (batch_size, channels, frames, height, width)\n",
    "    output = feature_extractor(dummy_input)\n",
    "    print(f\"Final feature shape: {output.shape}\")  # Expected output: [1, 2048, 1, 1, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract segments\n",
    "import cv2\n",
    "def extract_segments_from_video(video_path, segment_size=16, target_shape=(240, 320), frame_skip=10):\n",
    "    \"\"\"\n",
    "    Extracts video segments with frame skipping and efficient memory usage.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the video file.\n",
    "        segment_size (int): Number of frames per segment.\n",
    "        target_shape (tuple): Target resolution (height, width) for frames.\n",
    "        frame_skip (int): Number of frames to skip during extraction.\n",
    "\n",
    "    Returns:\n",
    "        list: List of segments, where each segment is a tensor of shape [C, T, H, W].\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Unable to open video file: {video_path}\")\n",
    "        \n",
    "        segments = []\n",
    "        frames = []\n",
    "        frame_count = 0\n",
    "\n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            # Skip frames based on frame_skip value\n",
    "            if frame_count % frame_skip != 0:\n",
    "                frame_count += 1\n",
    "                continue\n",
    "\n",
    "            # Resize frame and convert to tensor\n",
    "            frame = cv2.resize(frame, target_shape)\n",
    "            frame_tensor = torch.tensor(frame).permute(2, 0, 1).float() / 255.0  # Normalize to [0, 1]\n",
    "            frames.append(frame_tensor)\n",
    "\n",
    "            # Create a segment if enough frames are collected\n",
    "            if len(frames) == segment_size:\n",
    "                segments.append(torch.stack(frames, dim=1))  # Stack frames [C, T, H, W]\n",
    "                frames = []\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "        # Handle leftover frames (pad to segment size)\n",
    "        if frames:\n",
    "            while len(frames) < segment_size:\n",
    "                frames.append(torch.zeros_like(frames[0]))  # Pad with black frames\n",
    "            segments.append(torch.stack(frames, dim=1))\n",
    "\n",
    "        cap.release()\n",
    "        return segments\n",
    "\n",
    "    except Exception as e:\n",
    "        cap.release()\n",
    "        print(f\"Error processing video {video_path}: {e}\")\n",
    "        raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments divided into batches\n",
    "from torch.amp import autocast\n",
    "import tqdm\n",
    "video_path=r\"E:\\MIL\\Dataset\\Anomaly-Videos\\Anomaly-Videos-Part-2\\Explosion\\Explosion002_x264.mp4\"\n",
    "segment=extract_segments_from_video(video_path,frame_skip=3)\n",
    "batch_size=4\n",
    "batches = [segment[i:i + batch_size] for i in range(0, len(segment), batch_size)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  10%|▉         | 2/21 [00:00<00:05,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  14%|█▍        | 3/21 [00:00<00:04,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  24%|██▍       | 5/21 [00:01<00:02,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  29%|██▊       | 6/21 [00:01<00:02,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  38%|███▊      | 8/21 [00:01<00:01,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  48%|████▊     | 10/21 [00:01<00:01,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  67%|██████▋   | 14/21 [00:02<00:00,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  76%|███████▌  | 16/21 [00:02<00:00,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  86%|████████▌ | 18/21 [00:02<00:00,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  95%|█████████▌| 20/21 [00:02<00:00,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 21/21 [00:02<00:00,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# extract features \n",
    "from tqdm import tqdm\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "debug =True\n",
    "features = []\n",
    "for batch in tqdm(batches, desc=\"Extracting Features\"):\n",
    "    batch = torch.stack(batch).to(device)  # Convert batch to tensor\n",
    "    print(f\"Batch shape: {batch.shape}\") if debug else None\n",
    "\n",
    "    with autocast(\"cuda\"):\n",
    "        batch_features = extract_features(batch, device)  # Extract features\n",
    "        print(f'batch_feature[0]:{batch_features[0].shape}')\n",
    "\n",
    "    if isinstance(batch_features, list):\n",
    "        batch_features = torch.stack(batch_features)  # Ensure tensor type\n",
    "    features.append(batch_features.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list=features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_1520\\1178720715.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data=torch.load(video_1)\n"
     ]
    }
   ],
   "source": [
    "video_1=r\"E:\\MIL\\Code\\debug_processed_features\\Explosion002_x264_features.pt\"\n",
    "data=torch.load(video_1)\n",
    "features=data.get(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Features Shape: torch.Size([84, 2048, 1, 1, 1])\n",
      "Processed video: Explosion002_x264, Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Combine features from all batches\n",
    "import os\n",
    "features = torch.cat(features_list, dim=0)\n",
    "label=1\n",
    "output_dir=r\"E:\\MIL\\Code\\debug_processed_features\"\n",
    "print(f\"Combined Features Shape: {features.shape}\") if debug else None\n",
    "\n",
    "# Step 5: Save features and labels\n",
    "video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "torch.save({\n",
    "    \"features\": features,  # Tensor containing extracted features\n",
    "    \"label\": label  # Label associated with the video\n",
    "}, os.path.join(output_dir, f\"{video_name}_features.pt\"))\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"Processed video: {video_name}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "def combined_loss(scores, labels, lamda_sparsity=8e-5, lamda_smooth=8e-5):\n",
    "    \"\"\"\n",
    "    Calculates the combined loss function for weakly-supervised MIL anomaly detection.\n",
    "\n",
    "    The combined loss consists of:\n",
    "    1. Binary Cross-Entropy Loss with Logits:\n",
    "       - This is the classification loss that measures how well the model predicts the \n",
    "         anomaly scores for each segment. It internally applies the sigmoid function \n",
    "         to convert logits into probabilities before calculating the loss.\n",
    "    \n",
    "    2. Sparsity Loss:\n",
    "       - This encourages sparsity in anomaly predictions by penalizing the sum of \n",
    "         predicted probabilities across all segments. It helps the model focus on \n",
    "         a small number of segments likely to contain anomalies.\n",
    "\n",
    "    3. Smoothness Loss:\n",
    "       - This penalizes abrupt changes in predictions across adjacent segments \n",
    "         to ensure temporal smoothness in the predicted anomaly scores.\n",
    "\n",
    "    Parameters:\n",
    "    - scores (torch.Tensor): Predicted logits from the model. Shape: [num_segments].\n",
    "    - labels (torch.Tensor): Ground truth labels. Shape: [num_segments].\n",
    "    - lamda_sparsity (float): Weight for sparsity loss. Default: 8e-5.\n",
    "    - lamda_smooth (float): Weight for smoothness loss. Default: 8e-5.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: The combined loss value.\n",
    "    \"\"\"\n",
    "    # Binary Cross-Entropy Loss with Logits (handles sigmoid internally)\n",
    "    ce_loss = nn.BCEWithLogitsLoss()(scores, labels)\n",
    "\n",
    "    # Sparsity Loss: Penalizes the sum of predicted probabilities (encourages sparse anomaly detection)\n",
    "    sparsity_loss = lamda_sparsity * torch.sum(torch.sigmoid(scores))\n",
    "\n",
    "    # Smoothness Loss: Penalizes abrupt changes in adjacent segment predictions\n",
    "    smoothness_loss = lamda_smooth * torch.sum((torch.sigmoid(scores[1:]) - torch.sigmoid(scores[:-1])) ** 2)\n",
    "\n",
    "    # Combined loss\n",
    "    return ce_loss + sparsity_loss + smoothness_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequentialMILModel Initialized\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import GradScaler\n",
    "\n",
    "\n",
    "class SequentialMILModel(nn.Module):\n",
    "    def __init__(self, input_dim=2048, hidden_dim=512):\n",
    "        \"\"\"\n",
    "        Initializes a Sequential MIL Model for anomaly detection.\n",
    "\n",
    "        Parameters:\n",
    "        - input_dim (int): Input feature dimension (default: 2048).\n",
    "        - hidden_dim (int): Hidden layer dimension (default: 512).\n",
    "        \"\"\"\n",
    "        super(SequentialMILModel, self).__init__()\n",
    "        print(\"SequentialMILModel Initialized\")  # Debug print\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, 32)         # Second fully connected layer\n",
    "        self.fc3 = nn.Linear(32, 1)                 # Final output layer\n",
    "        self.dropout = nn.Dropout(0.6)              # Dropout with probability 0.6\n",
    "        self.relu = nn.ReLU()                       # ReLU activation\n",
    "        self.sigmoid = nn.Sigmoid()                 # Sigmoid activation for output\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "\n",
    "        Parameters:\n",
    "        - x (torch.Tensor): Input features of shape [num_segments, input_dim].\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Raw logits for each segment. Shape: [num_segments, 1].\n",
    "        \"\"\"\n",
    "        print(f\"Input shape: {x.shape}\")  # Debugging statement\n",
    "        # Pass input through layers with activation and dropout\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        hidden = x  # Optional: retain hidden layer output for debugging or analysis\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        return x.squeeze(-1)  # Squeeze the last dimension to return [num_segments]\n",
    "    \n",
    "model= SequentialMILModel(input_dim=2048).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scaler = GradScaler()  # Gradient scaler for mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape after reshaping: torch.Size([84, 2048])\n",
      "Input shape: torch.Size([84, 2048])\n"
     ]
    }
   ],
   "source": [
    "# Ensure the model is on the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "# Ensure features are on the same device\n",
    "features = features.to(dtype=torch.float32)\n",
    "\n",
    "features = features.to(device)\n",
    "\n",
    "# it is processing 675 *2048 to avoid this I am just taking 2048,1,1,1\n",
    "if features.dim() > 2:\n",
    "    features = features.view(features.size(0), -1)\n",
    "    print(f\"Features shape after reshaping: {features.shape}\")\n",
    "\n",
    "# Now perform the forward pass\n",
    "scores = model(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3111, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.tensor([0], dtype=torch.float32, device=scores.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_score = torch.max(scores)  # Replace with torch.mean(segment_scores) if needed\n",
    "video_score=video_score.unsqueeze(0)\n",
    "\n",
    "# Calculate loss using video-level score and label\n",
    "loss = combined_loss(video_score, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate segment scores into a video-level score\n",
    "video_score = torch.max(scores)  # Replace with torch.mean(scores) if needed\n",
    "\n",
    "# Convert the label to a tensor and ensure the shapes match\n",
    "label = torch.tensor([0], dtype=torch.float32, device=video_score.device)\n",
    "\n",
    "# Expand video_score to match label shape\n",
    "video_score = video_score.unsqueeze(0)  # Convert shape from [] to [1]\n",
    "\n",
    "# Calculate loss using video-level score and label\n",
    "loss = combined_loss(video_score, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5498, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5349], device='cuda:0', grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(scores).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1952, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 675 segments from video E:\\MIL\\Dataset\\Normal-Videos-Part-1\\Normal_Videos_924_x264.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Segments: 100%|██████████| 675/675 [00:00<00:00, 94804.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape before processing: torch.Size([3, 16, 320, 240])\n",
      "Segment shape after processing: torch.Size([3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   0%|          | 0/169 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   1%|          | 1/169 [00:00<01:41,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   1%|          | 2/169 [00:00<01:04,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   2%|▏         | 3/169 [00:01<00:56,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   2%|▏         | 4/169 [00:01<00:51,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   3%|▎         | 5/169 [00:01<00:51,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   4%|▎         | 6/169 [00:01<00:47,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   4%|▍         | 7/169 [00:02<00:46,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   5%|▍         | 8/169 [00:02<00:43,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   5%|▌         | 9/169 [00:02<00:46,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   6%|▌         | 10/169 [00:03<00:44,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   7%|▋         | 11/169 [00:03<00:41,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   7%|▋         | 12/169 [00:03<00:42,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   8%|▊         | 13/169 [00:03<00:40,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   8%|▊         | 14/169 [00:04<00:40,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   9%|▉         | 15/169 [00:04<00:40,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   9%|▉         | 16/169 [00:04<00:42,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  10%|█         | 17/169 [00:04<00:41,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  11%|█         | 18/169 [00:05<00:40,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  11%|█         | 19/169 [00:05<00:39,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  12%|█▏        | 20/169 [00:05<00:38,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  12%|█▏        | 21/169 [00:05<00:36,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  13%|█▎        | 22/169 [00:06<00:36,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  14%|█▎        | 23/169 [00:06<00:35,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  14%|█▍        | 24/169 [00:06<00:36,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  15%|█▍        | 25/169 [00:06<00:36,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  15%|█▌        | 26/169 [00:07<00:36,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  16%|█▌        | 27/169 [00:07<00:35,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  17%|█▋        | 28/169 [00:07<00:35,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  17%|█▋        | 29/169 [00:07<00:35,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  18%|█▊        | 30/169 [00:08<00:35,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  18%|█▊        | 31/169 [00:08<00:35,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  19%|█▉        | 32/169 [00:08<00:35,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  20%|█▉        | 33/169 [00:08<00:35,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  20%|██        | 34/169 [00:09<00:34,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  21%|██        | 35/169 [00:09<00:34,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  21%|██▏       | 36/169 [00:09<00:34,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  22%|██▏       | 37/169 [00:09<00:33,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  22%|██▏       | 38/169 [00:10<00:33,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  23%|██▎       | 39/169 [00:10<00:33,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  24%|██▎       | 40/169 [00:10<00:32,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  24%|██▍       | 41/169 [00:10<00:32,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  25%|██▍       | 42/169 [00:11<00:34,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  25%|██▌       | 43/169 [00:11<00:33,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  26%|██▌       | 44/169 [00:11<00:32,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  27%|██▋       | 45/169 [00:12<00:30,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  27%|██▋       | 46/169 [00:12<00:30,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  28%|██▊       | 47/169 [00:12<00:29,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  28%|██▊       | 48/169 [00:12<00:30,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  29%|██▉       | 49/169 [00:13<00:30,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  30%|██▉       | 50/169 [00:13<00:30,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  30%|███       | 51/169 [00:13<00:30,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  31%|███       | 52/169 [00:13<00:30,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  31%|███▏      | 53/169 [00:14<00:29,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  32%|███▏      | 54/169 [00:14<00:29,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  33%|███▎      | 55/169 [00:14<00:28,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  33%|███▎      | 56/169 [00:14<00:29,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  34%|███▎      | 57/169 [00:15<00:28,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  34%|███▍      | 58/169 [00:15<00:28,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  35%|███▍      | 59/169 [00:15<00:28,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  36%|███▌      | 60/169 [00:15<00:27,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  36%|███▌      | 61/169 [00:16<00:27,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  37%|███▋      | 62/169 [00:16<00:27,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  37%|███▋      | 63/169 [00:16<00:27,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  38%|███▊      | 64/169 [00:16<00:26,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  38%|███▊      | 65/169 [00:17<00:25,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  39%|███▉      | 66/169 [00:17<00:25,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  40%|███▉      | 67/169 [00:17<00:25,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  40%|████      | 68/169 [00:17<00:25,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  41%|████      | 69/169 [00:18<00:25,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  41%|████▏     | 70/169 [00:18<00:24,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  42%|████▏     | 71/169 [00:18<00:24,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  43%|████▎     | 72/169 [00:18<00:24,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  43%|████▎     | 73/169 [00:19<00:23,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  44%|████▍     | 74/169 [00:19<00:24,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  44%|████▍     | 75/169 [00:19<00:23,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  45%|████▍     | 76/169 [00:19<00:23,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  46%|████▌     | 77/169 [00:20<00:24,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  46%|████▌     | 78/169 [00:20<00:23,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  47%|████▋     | 79/169 [00:20<00:23,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  47%|████▋     | 80/169 [00:20<00:23,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  48%|████▊     | 81/169 [00:21<00:23,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  49%|████▊     | 82/169 [00:21<00:22,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  49%|████▉     | 83/169 [00:21<00:22,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  50%|████▉     | 84/169 [00:21<00:22,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  50%|█████     | 85/169 [00:22<00:21,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  51%|█████     | 86/169 [00:22<00:21,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  51%|█████▏    | 87/169 [00:22<00:21,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  52%|█████▏    | 88/169 [00:23<00:21,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  53%|█████▎    | 89/169 [00:23<00:21,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  53%|█████▎    | 90/169 [00:23<00:21,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  54%|█████▍    | 91/169 [00:23<00:20,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  54%|█████▍    | 92/169 [00:24<00:20,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  55%|█████▌    | 93/169 [00:24<00:19,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  56%|█████▌    | 94/169 [00:24<00:19,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  56%|█████▌    | 95/169 [00:24<00:18,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  57%|█████▋    | 96/169 [00:25<00:18,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  57%|█████▋    | 97/169 [00:25<00:18,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  58%|█████▊    | 98/169 [00:25<00:17,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  59%|█████▊    | 99/169 [00:25<00:17,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  59%|█████▉    | 100/169 [00:26<00:17,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  60%|█████▉    | 101/169 [00:26<00:17,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  60%|██████    | 102/169 [00:26<00:16,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  61%|██████    | 103/169 [00:26<00:16,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  62%|██████▏   | 104/169 [00:27<00:16,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  62%|██████▏   | 105/169 [00:27<00:16,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  63%|██████▎   | 106/169 [00:27<00:16,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  63%|██████▎   | 107/169 [00:27<00:15,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  64%|██████▍   | 108/169 [00:28<00:15,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  64%|██████▍   | 109/169 [00:28<00:15,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  65%|██████▌   | 110/169 [00:28<00:14,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  66%|██████▌   | 111/169 [00:28<00:14,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  66%|██████▋   | 112/169 [00:29<00:14,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  67%|██████▋   | 113/169 [00:29<00:14,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  67%|██████▋   | 114/169 [00:29<00:14,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  68%|██████▊   | 115/169 [00:29<00:13,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  69%|██████▊   | 116/169 [00:30<00:13,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  69%|██████▉   | 117/169 [00:30<00:13,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  70%|██████▉   | 118/169 [00:30<00:12,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  70%|███████   | 119/169 [00:30<00:12,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  71%|███████   | 120/169 [00:31<00:12,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  72%|███████▏  | 121/169 [00:31<00:11,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  72%|███████▏  | 122/169 [00:31<00:11,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  73%|███████▎  | 123/169 [00:31<00:11,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  73%|███████▎  | 124/169 [00:32<00:10,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  74%|███████▍  | 125/169 [00:32<00:10,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  75%|███████▍  | 126/169 [00:32<00:10,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  75%|███████▌  | 127/169 [00:32<00:10,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  76%|███████▌  | 128/169 [00:33<00:10,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  76%|███████▋  | 129/169 [00:33<00:09,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  77%|███████▋  | 130/169 [00:33<00:09,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  78%|███████▊  | 131/169 [00:33<00:09,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  78%|███████▊  | 132/169 [00:34<00:09,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  79%|███████▊  | 133/169 [00:34<00:09,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  79%|███████▉  | 134/169 [00:34<00:08,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  80%|███████▉  | 135/169 [00:34<00:08,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  80%|████████  | 136/169 [00:35<00:08,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  81%|████████  | 137/169 [00:35<00:07,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  82%|████████▏ | 138/169 [00:35<00:07,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  82%|████████▏ | 139/169 [00:35<00:07,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  83%|████████▎ | 140/169 [00:36<00:07,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  83%|████████▎ | 141/169 [00:36<00:06,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  84%|████████▍ | 142/169 [00:36<00:06,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  85%|████████▍ | 143/169 [00:36<00:06,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  85%|████████▌ | 144/169 [00:37<00:06,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  86%|████████▌ | 145/169 [00:37<00:05,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  86%|████████▋ | 146/169 [00:37<00:05,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  87%|████████▋ | 147/169 [00:37<00:05,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  88%|████████▊ | 148/169 [00:38<00:05,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  88%|████████▊ | 149/169 [00:38<00:05,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  89%|████████▉ | 150/169 [00:38<00:04,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  89%|████████▉ | 151/169 [00:38<00:04,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  90%|████████▉ | 152/169 [00:39<00:04,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  91%|█████████ | 153/169 [00:39<00:03,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  91%|█████████ | 154/169 [00:39<00:03,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  92%|█████████▏| 155/169 [00:39<00:03,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  92%|█████████▏| 156/169 [00:40<00:03,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  93%|█████████▎| 157/169 [00:40<00:02,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  93%|█████████▎| 158/169 [00:40<00:02,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  94%|█████████▍| 159/169 [00:40<00:02,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  95%|█████████▍| 160/169 [00:41<00:02,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  95%|█████████▌| 161/169 [00:41<00:01,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  96%|█████████▌| 162/169 [00:41<00:01,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  96%|█████████▋| 163/169 [00:41<00:01,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  97%|█████████▋| 164/169 [00:42<00:01,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  98%|█████████▊| 165/169 [00:42<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  98%|█████████▊| 166/169 [00:42<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  99%|█████████▉| 167/169 [00:42<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([4, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:  99%|█████████▉| 168/169 [00:43<00:00,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Batch shape: torch.Size([3, 3, 16, 320, 240])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 169/169 [00:43<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 16, 320, 240])\n",
      "After backbone shape: torch.Size([1, 192, 16, 10, 8])\n",
      "After final_block shape: torch.Size([1, 2048, 4, 6, 4])\n",
      "After pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "After global average pooling shape: torch.Size([1, 2048, 1, 1, 1])\n",
      "batch_feature[0]:torch.Size([2048, 1, 1, 1])\n",
      "Combined Features Shape: torch.Size([675, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed video: Normal_Videos_924_x264, Label: 0\n",
      "File: debug_processed_features\\Normal_Videos_924_x264_features.pt\n",
      "Features shape: torch.Size([675, 2048, 1, 1, 1])\n",
      "Features type: torch.float16\n",
      "Label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_18648\\833238633.py:100: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(file_path)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast  # For mixed-precision acceleration\n",
    "\n",
    "# Define paths and directories\n",
    "video_path = r\"E:\\MIL\\Dataset\\Normal-Videos-Part-1\\Normal_Videos_924_x264.mp4\"  # Specific video to process\n",
    "output_dir = 'debug_processed_features'  # Output directory for processed features\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "\n",
    "# Set the device (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define batch size for segment processing\n",
    "batch_size = 4  # Start small to avoid OOM errors\n",
    "\n",
    "# Debugging flag\n",
    "debug = True\n",
    "\n",
    "# Processing the specific video\n",
    "try:\n",
    "      # Assign label manually since we are processing a single video\n",
    "\n",
    "    # Ensure video file exists\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
    "\n",
    "    # Step 1: Extract segments from the video\n",
    "    segments = extract_segments_from_video(video_path)  # List of segments\n",
    "    print(f\"Extracted {len(segments)} segments from video {video_path}\") if debug else None\n",
    "\n",
    "    # Step 2: Process segments to ensure uniform shape\n",
    "    processed_segments = []\n",
    "    for segment in tqdm(segments, desc=\"Processing Segments\"):\n",
    "        print(f\"Segment shape before processing: {segment.shape}\") if debug else None\n",
    "        if segment.size(1) < 16:  # If fewer than 16 frames\n",
    "            pad_size = 16 - segment.size(1)\n",
    "            padding = torch.zeros((segment.size(0), pad_size, segment.size(2), segment.size(3)))\n",
    "            segment = torch.cat([segment, padding], dim=1)\n",
    "        elif segment.size(1) > 16:  # If more than 16 frames\n",
    "            segment = segment[:, :16, :, :]\n",
    "        print(f\"Segment shape after processing: {segment.shape}\") if debug else None\n",
    "        processed_segments.append(segment)\n",
    "    segments = processed_segments\n",
    "\n",
    "    # Step 3: Divide into batches\n",
    "    batches = [segments[i:i + batch_size] for i in range(0, len(segments), batch_size)]\n",
    "\n",
    "    # Step 4: Extract features for each batch\n",
    "    features = []\n",
    "    for batch in tqdm(batches, desc=\"Extracting Features\"):\n",
    "        batch = torch.stack(batch).to(device)  # Convert batch to tensor\n",
    "        print(f\"Batch shape: {batch.shape}\") if debug else None\n",
    "\n",
    "        with autocast(\"cuda\"):\n",
    "            batch_features = extract_features(batch, device)  # Extract features\n",
    "            print(f'batch_feature[0]:{batch_features[0].shape}')\n",
    "\n",
    "        if isinstance(batch_features, list):\n",
    "            batch_features = torch.stack(batch_features)  # Ensure tensor type\n",
    "        features.append(batch_features.cpu())\n",
    "\n",
    "    # Combine features from all batches\n",
    "    features = torch.cat(features, dim=0)\n",
    "    print(f\"Combined Features Shape: {features.shape}\") if debug else None\n",
    "\n",
    "    # Step 5: Save features and labels\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    torch.save({\n",
    "        \"features\": features,  # Tensor containing extracted features\n",
    "        \"label\": label  # Label associated with the video\n",
    "    }, os.path.join(output_dir, f\"{video_name}_features.pt\"))\n",
    "\n",
    "    # Clear GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Processed video: {video_name}, Label: {label}\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e):\n",
    "        print(f\"CUDA out of memory error while processing {video_path}. Reducing batch size...\")\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        print(f\"RuntimeError: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing video {video_path}: {e}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Debugging function\n",
    "def debug_feature_and_label(file_path):\n",
    "    \"\"\"\n",
    "    Debugging function to inspect the features and label in the saved .pt file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the .pt file to inspect.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the .pt file\n",
    "        data = torch.load(file_path)\n",
    "\n",
    "        # Extract features and label\n",
    "        features = data.get(\"features\", None)\n",
    "        label = data.get(\"label\", None)\n",
    "\n",
    "        # Debug information\n",
    "        print(f\"File: {file_path}\")\n",
    "        if features is not None:\n",
    "            print(f\"Features shape: {features.shape}\")\n",
    "            print(f\"Features type: {features.dtype}\")\n",
    "        else:\n",
    "            print(\"No features found in the .pt file.\")\n",
    "\n",
    "        if label is not None:\n",
    "            print(f\"Label: {label}\")\n",
    "        else:\n",
    "            print(\"No label found in the .pt file.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading .pt file {file_path}: {e}\")\n",
    "\n",
    "# Example debug call for the processed .pt file\n",
    "debug_feature_and_label(os.path.join(output_dir, \"Normal_Videos_924_x264_features.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast  # For mixed-precision acceleration\n",
    "\n",
    "# Define paths and directories\n",
    "video_path = r\"E:\\MIL\\Dataset\\Normal-Videos-Part-1\\Normal_Videos_924_x264.mp4\"  # Specific video to process\n",
    "output_dir = 'debug_processed_features'  # Output directory for processed features\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "\n",
    "# Set the device (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define batch size for segment processing\n",
    "batch_size = 4  # Start small to avoid OOM errors\n",
    "\n",
    "# Debugging flag\n",
    "debug = True\n",
    "\n",
    "# Processing the specific video\n",
    "try:\n",
    "      # Assign label manually since we are processing a single video\n",
    "\n",
    "    # Ensure video file exists\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
    "\n",
    "    # Step 1: Extract segments from the video\n",
    "    segments = extract_segments_from_video(video_path)  # List of segments\n",
    "    print(f\"Extracted {len(segments)} segments from video {video_path}\") if debug else None\n",
    "\n",
    "    # Step 2: Process segments to ensure uniform shape\n",
    "    processed_segments = []\n",
    "    for segment in tqdm(segments, desc=\"Processing Segments\"):\n",
    "        print(f\"Segment shape before processing: {segment.shape}\") if debug else None\n",
    "        if segment.size(1) < 16:  # If fewer than 16 frames\n",
    "            pad_size = 16 - segment.size(1)\n",
    "            padding = torch.zeros((segment.size(0), pad_size, segment.size(2), segment.size(3)))\n",
    "            segment = torch.cat([segment, padding], dim=1)\n",
    "        elif segment.size(1) > 16:  # If more than 16 frames\n",
    "            segment = segment[:, :16, :, :]\n",
    "        print(f\"Segment shape after processing: {segment.shape}\") if debug else None\n",
    "        processed_segments.append(segment)\n",
    "    segments = processed_segments\n",
    "\n",
    "    # Step 3: Divide into batches\n",
    "    batches = [segments[i:i + batch_size] for i in range(0, len(segments), batch_size)]\n",
    "\n",
    "    # Step 4: Extract features for each batch\n",
    "    features = []\n",
    "    for batch in tqdm(batches, desc=\"Extracting Features\"):\n",
    "        batch = torch.stack(batch).to(device)  # Convert batch to tensor\n",
    "        print(f\"Batch shape: {batch.shape}\") if debug else None\n",
    "\n",
    "        with autocast(\"cuda\"):\n",
    "            batch_features = extract_features(batch, device)  # Extract features\n",
    "            print(f'batch_feature[0]:{batch_features[0].shape}')\n",
    "\n",
    "        if isinstance(batch_features, list):\n",
    "            batch_features = torch.stack(batch_features)  # Ensure tensor type\n",
    "        features.append(batch_features.cpu())\n",
    "\n",
    "    # Combine features from all batches\n",
    "    features = torch.cat(features, dim=0)\n",
    "    print(f\"Combined Features Shape: {features.shape}\") if debug else None\n",
    "\n",
    "    # Step 5: Save features and labels\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    torch.save({\n",
    "        \"features\": features,  # Tensor containing extracted features\n",
    "        \"label\": label  # Label associated with the video\n",
    "    }, os.path.join(output_dir, f\"{video_name}_features.pt\"))\n",
    "\n",
    "    # Clear GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Processed video: {video_name}, Label: {label}\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e):\n",
    "        print(f\"CUDA out of memory error while processing {video_path}. Reducing batch size...\")\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        print(f\"RuntimeError: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing video {video_path}: {e}\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Debugging function\n",
    "def debug_feature_and_label(file_path):\n",
    "    \"\"\"\n",
    "    Debugging function to inspect the features and label in the saved .pt file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the .pt file to inspect.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the .pt file\n",
    "        data = torch.load(file_path)\n",
    "\n",
    "        # Extract features and label\n",
    "        features = data.get(\"features\", None)\n",
    "        label = data.get(\"label\", None)\n",
    "\n",
    "        # Debug information\n",
    "        print(f\"File: {file_path}\")\n",
    "        if features is not None:\n",
    "            print(f\"Features shape: {features.shape}\")\n",
    "            print(f\"Features type: {features.dtype}\")\n",
    "        else:\n",
    "            print(\"No features found in the .pt file.\")\n",
    "\n",
    "        if label is not None:\n",
    "            print(f\"Label: {label}\")\n",
    "        else:\n",
    "            print(\"No label found in the .pt file.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading .pt file {file_path}: {e}\")\n",
    "\n",
    "# Example debug call for the processed .pt file\n",
    "debug_feature_and_label(os.path.join(output_dir, \"Normal_Videos_924_x264_features.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as torch_init\n",
    "\n",
    "# Function to initialize weights\n",
    "def weight_init(m):\n",
    "    \"\"\"\n",
    "    Xavier Initialization\n",
    "    -------------------------------------------------------------------\n",
    "    Xavier initialization is a technique for initializing the weights of neural networks\n",
    "    in a way that facilitates efficient training. It is named after Xavier Glorot, \n",
    "    who introduced this method in a 2010 paper co-authored with Yoshua Bengio. In their\n",
    "    influential research paper titled \"Understanding the Challenges of Training Deep Feedforward \n",
    "    Neural Networks,\" the authors conducted experiments to investigate a widely accepted rule of thumb in the \n",
    "    field of deep learning. This rule involves initializing the weights of neural networks by selecting \n",
    "    random values from a uniform distribution that ranges between -1 and 1. After this random initialization, \n",
    "    the weights are then scaled down by a factor of 1 divided by the square root of the number of input units (denoted as 'n').\n",
    "    --------------------------------------------------------------------\n",
    "    TL DR\n",
    "    Initialize weights for Conv and Linear layers using Xavier initialization.\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 or classname.find('Linear') != -1:\n",
    "        torch_init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "class SequentialMILModel(nn.Module):\n",
    "    def __init__(self, input_dim=2048, hidden_dim=512):\n",
    "        \"\"\"\n",
    "        Initializes a Sequential MIL Model for anomaly detection.\n",
    "\n",
    "        Parameters:\n",
    "        - input_dim (int): Input feature dimension (default: 2048).\n",
    "        - hidden_dim (int): Hidden layer dimension (default: 512).\n",
    "        \"\"\"\n",
    "        super(SequentialMILModel, self).__init__()\n",
    "        print(\"SequentialMILModel Initialized\")  # Debug print\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, 32)         # Second fully connected layer\n",
    "        self.fc3 = nn.Linear(32, 1)                 # Final output layer\n",
    "        self.dropout = nn.Dropout(0.6)              # Dropout with probability 0.6\n",
    "        self.relu = nn.ReLU()                       # ReLU activation\n",
    "        self.sigmoid = nn.Sigmoid()                 # Sigmoid activation for output\n",
    "\n",
    "        # Apply the weight initialization\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "\n",
    "        Parameters:\n",
    "        - x (torch.Tensor): Input features of shape [num_segments, input_dim].\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Raw logits for each segment. Shape: [num_segments, 1].\n",
    "        \"\"\"\n",
    "        print(f\"Input shape: {x.shape}\")  # Debugging statement\n",
    "        # Pass input through layers with activation and dropout\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        hidden = x  # Optional: retain hidden layer output for debugging or analysis\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        return x.squeeze(-1)  # Squeeze the last dimension to return [num_segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_32540\\2342307387.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data1 = torch.load(file1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.8594\n",
      "Euclidean Distance: 3.8633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_32540\\2342307387.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data2 = torch.load(file2)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "def compare_features(file1, file2):\n",
    "    \"\"\"\n",
    "    Compares the similarity between two feature files.\n",
    "\n",
    "    Args:\n",
    "        file1 (str): Path to the first feature file.\n",
    "        file2 (str): Path to the second feature file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains cosine similarity and Euclidean distance.\n",
    "    \"\"\"\n",
    "    # Load features from the files\n",
    "    data1 = torch.load(file1)\n",
    "    data2 = torch.load(file2)\n",
    "\n",
    "    features1 = data1[\"features\"]\n",
    "    features2 = data2[\"features\"]\n",
    "\n",
    "    # Reshape features to 2D (if necessary) and normalize\n",
    "    features1 = features1.view(features1.size(0), -1)  # [segments, feature_dim]\n",
    "    features2 = features2.view(features2.size(0), -1)\n",
    "\n",
    "    # Compute similarity metrics\n",
    "    cosine_similarity = F.cosine_similarity(features1.mean(dim=0), features2.mean(dim=0), dim=0).item()\n",
    "    euclidean_distance = torch.norm(features1.mean(dim=0) - features2.mean(dim=0)).item()\n",
    "\n",
    "    return {\n",
    "        \"cosine_similarity\": cosine_similarity,\n",
    "        \"euclidean_distance\": euclidean_distance,\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "file1 = r\"E:\\MIL\\Code\\normal_features\\Normal_Videos165_x264_features.pt\"\n",
    "file2 = r\"E:\\MIL\\Code\\normal_features\\Normal_Videos_059_x264_features.pt\"\n",
    "results = compare_features(file1, file2)\n",
    "\n",
    "print(f\"Cosine Similarity: {results['cosine_similarity']:.4f}\")\n",
    "print(f\"Euclidean Distance: {results['euclidean_distance']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_32540\\1000071045.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(file_path)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (182272) must match the size of tensor b (30720) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m features \u001b[38;5;241m=\u001b[39m load_features(normal_dir)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Step 2: Calculate pairwise similarity\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m similarity_results \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_pairwise_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Step 3: Analyze similarity\u001b[39;00m\n\u001b[0;32m     88\u001b[0m analysis \u001b[38;5;241m=\u001b[39m analyze_similarity(similarity_results)\n",
      "Cell \u001b[1;32mIn[3], line 42\u001b[0m, in \u001b[0;36mcalculate_pairwise_similarity\u001b[1;34m(features)\u001b[0m\n\u001b[0;32m     39\u001b[0m feat2 \u001b[38;5;241m=\u001b[39m features[file2]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Cosine Similarity\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m cosine_similarity \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Euclidean Distance\u001b[39;00m\n\u001b[0;32m     45\u001b[0m euclidean_distance \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(feat1 \u001b[38;5;241m-\u001b[39m feat2)\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (182272) must match the size of tensor b (30720) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "\n",
    "def load_features(directory):\n",
    "    \"\"\"\n",
    "    Load all feature files from a directory into a dictionary.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing feature files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping file names to their features.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".pt\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            data = torch.load(file_path)\n",
    "            features[file] = data[\"features\"]\n",
    "    return features\n",
    "\n",
    "def calculate_pairwise_similarity(features):\n",
    "    \"\"\"\n",
    "    Calculate pairwise similarity scores for all feature files.\n",
    "\n",
    "    Args:\n",
    "        features (dict): Dictionary of feature tensors.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (file1, file2, cosine_similarity, euclidean_distance).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    file_pairs = itertools.combinations(features.keys(), 2)  # Generate all pairs of files\n",
    "\n",
    "    for file1, file2 in file_pairs:\n",
    "        feat1 = features[file1].view(-1).float()\n",
    "        feat2 = features[file2].view(-1).float()\n",
    "\n",
    "        # Cosine Similarity\n",
    "        cosine_similarity = F.cosine_similarity(feat1, feat2, dim=0).item()\n",
    "\n",
    "        # Euclidean Distance\n",
    "        euclidean_distance = torch.norm(feat1 - feat2).item()\n",
    "\n",
    "        results.append((file1, file2, cosine_similarity, euclidean_distance))\n",
    "\n",
    "    return results\n",
    "\n",
    "def analyze_similarity(results, cosine_threshold=0.85, distance_threshold=5):\n",
    "    \"\"\"\n",
    "    Analyze the similarity results and determine if augmentation is needed.\n",
    "\n",
    "    Args:\n",
    "        results (list): List of similarity results.\n",
    "        cosine_threshold (float): Threshold for cosine similarity.\n",
    "        distance_threshold (float): Threshold for Euclidean distance.\n",
    "\n",
    "    Returns:\n",
    "        dict: Analysis summary.\n",
    "    \"\"\"\n",
    "    similar_pairs = [r for r in results if r[2] > cosine_threshold and r[3] < distance_threshold]\n",
    "    total_pairs = len(results)\n",
    "    similarity_ratio = len(similar_pairs) / total_pairs\n",
    "\n",
    "    print(f\"Total Pairs: {total_pairs}\")\n",
    "    print(f\"Similar Pairs (Cosine > {cosine_threshold}, Distance < {distance_threshold}): {len(similar_pairs)}\")\n",
    "    print(f\"Similarity Ratio: {similarity_ratio:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"total_pairs\": total_pairs,\n",
    "        \"similar_pairs\": len(similar_pairs),\n",
    "        \"similarity_ratio\": similarity_ratio,\n",
    "        \"similar_pairs_details\": similar_pairs,\n",
    "    }\n",
    "\n",
    "# Example Usage\n",
    "normal_dir = r\"E:\\MIL\\Code\\normal_features\"\n",
    "\n",
    "# Step 1: Load features\n",
    "features = load_features(normal_dir)\n",
    "\n",
    "# Step 2: Calculate pairwise similarity\n",
    "similarity_results = calculate_pairwise_similarity(features)\n",
    "\n",
    "# Step 3: Analyze similarity\n",
    "analysis = analyze_similarity(similarity_results)\n",
    "\n",
    "# Optionally, print detailed results\n",
    "for file1, file2, cosine_sim, euclidean_dist in similarity_results[:10]:  # Limit to top 10 pairs for display\n",
    "    print(f\"{file1} vs {file2}: Cosine={cosine_sim:.4f}, Euclidean={euclidean_dist:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating features:   0%|          | 0/200 [00:00<?, ?it/s]C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_32540\\676298021.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  features = torch.load(file)[\"features\"]\n",
      "Aggregating features: 100%|██████████| 200/200 [00:00<00:00, 1262.09it/s]\n",
      "Calculating similarities: 100%|██████████| 200/200 [00:01<00:00, 106.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores saved to e:\\MIL\\Code\\similarity_scores.txt\n",
      "Similarity scores and mean values saved to e:\\MIL\\Code\\similarity_scores.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def aggregate_features(feature_tensor, method=\"mean\"):\n",
    "    \"\"\"\n",
    "    Aggregates features across segments.\n",
    "\n",
    "    Args:\n",
    "        feature_tensor (torch.Tensor): Input feature tensor of shape [num_segments, feature_dim].\n",
    "        method (str): Aggregation method ('mean' or 'max').\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Aggregated feature tensor of shape [feature_dim].\n",
    "    \"\"\"\n",
    "    if method == \"mean\":\n",
    "        return torch.mean(feature_tensor, dim=0)  # Mean pooling\n",
    "    elif method == \"max\":\n",
    "        return torch.max(feature_tensor, dim=0).values  # Max pooling\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported aggregation method. Use 'mean' or 'max'.\")\n",
    "\n",
    "def calculate_similarity(feat1, feat2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity and Euclidean distance between two feature tensors.\n",
    "\n",
    "    Args:\n",
    "        feat1 (torch.Tensor): First feature tensor of shape [feature_dim].\n",
    "        feat2 (torch.Tensor): Second feature tensor of shape [feature_dim].\n",
    "\n",
    "    Returns:\n",
    "        tuple: Cosine similarity and Euclidean distance.\n",
    "    \"\"\"\n",
    "    # Cosine Similarity\n",
    "    cosine_similarity = F.cosine_similarity(feat1, feat2, dim=0).item()\n",
    "\n",
    "    # Euclidean Distance\n",
    "    euclidean_distance = torch.norm(feat1 - feat2).item()\n",
    "\n",
    "    return cosine_similarity, euclidean_distance\n",
    "\n",
    "def compute_similarity_scores(directory, method=\"mean\"):\n",
    "    \"\"\"\n",
    "    Compute similarity scores for all pairs of feature files in a directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing feature files.\n",
    "        method (str): Aggregation method ('mean' or 'max').\n",
    "\n",
    "    Returns:\n",
    "        list: A list of similarity scores (cosine similarity and Euclidean distance).\n",
    "    \"\"\"\n",
    "    feature_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".pt\")]\n",
    "    aggregated_features = {}\n",
    "\n",
    "    # Aggregate features for all files\n",
    "    for file in tqdm(feature_files, desc=\"Aggregating features\"):\n",
    "        features = torch.load(file)[\"features\"]\n",
    "        aggregated_features[file] = aggregate_features(features, method=method)\n",
    "\n",
    "    # Compute similarity scores\n",
    "    similarity_scores = []\n",
    "    for i, file1 in enumerate(tqdm(feature_files, desc=\"Calculating similarities\")):\n",
    "        for file2 in feature_files[i+1:]:\n",
    "            feat1 = aggregated_features[file1]\n",
    "            feat2 = aggregated_features[file2]\n",
    "            cos_sim, euc_dist = calculate_similarity(feat1, feat2)\n",
    "            similarity_scores.append({\n",
    "                \"file1\": file1,\n",
    "                \"file2\": file2,\n",
    "                \"cosine_similarity\": cos_sim,\n",
    "                \"euclidean_distance\": euc_dist\n",
    "            })\n",
    "\n",
    "    return similarity_scores\n",
    "\n",
    "# Directory containing normal features\n",
    "normal_feature_dir = r\"E:\\MIL\\Code\\normal_features\"\n",
    "\n",
    "# Compute similarity scores\n",
    "similarity_scores = compute_similarity_scores(normal_feature_dir, method=\"mean\")\n",
    "\n",
    "# calculate mean score\n",
    "def calculate_mean_scores(similarity_scores):\n",
    "    \"\"\"\n",
    "    Calculate the mean cosine similarity and Euclidean distance from similarity scores.\n",
    "\n",
    "    Args:\n",
    "        similarity_scores (list): List of dictionaries containing similarity metrics.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Mean cosine similarity and mean Euclidean distance.\n",
    "    \"\"\"\n",
    "    total_cosine_similarity = sum(score[\"cosine_similarity\"] for score in similarity_scores)\n",
    "    total_euclidean_distance = sum(score[\"euclidean_distance\"] for score in similarity_scores)\n",
    "    num_scores = len(similarity_scores)\n",
    "\n",
    "    mean_cosine_similarity = total_cosine_similarity / num_scores\n",
    "    mean_euclidean_distance = total_euclidean_distance / num_scores\n",
    "\n",
    "    return mean_cosine_similarity, mean_euclidean_distance\n",
    "\n",
    "# Save results to a file\n",
    "mean_cosine_similarity, mean_euclidean_distance = calculate_mean_scores(similarity_scores)\n",
    "\n",
    "# Save results to a file\n",
    "# Ensure output directory is valid and writable\n",
    "output_dir = os.getcwd()  # Use the current working directory\n",
    "output_file = os.path.join(output_dir, \"similarity_scores.txt\")\n",
    "\n",
    "try:\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for score in similarity_scores:\n",
    "            f.write(f\"Cosine Similarity: {score['cosine_similarity']:.4f}, Euclidean Distance: {score['euclidean_distance']:.4f}\\n\")\n",
    "    print(f\"Similarity scores saved to {output_file}\")\n",
    "except OSError as e:\n",
    "    print(f\"Error saving similarity scores: {e}\")\n",
    "\n",
    "# Append mean scores to the file\n",
    "with open(output_file, \"a\") as f:\n",
    "    f.write(f\"\\nMean Cosine Similarity: {mean_cosine_similarity:.4f}\\n\")\n",
    "    f.write(f\"Mean Euclidean Distance: {mean_euclidean_distance:.4f}\\n\")\n",
    "\n",
    "print(f\"Similarity scores and mean values saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7461692863732726"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7382878749214825"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement maptplotlib (from versions: none)\n",
      "ERROR: No matching distribution found for maptplotlib\n"
     ]
    }
   ],
   "source": [
    "pip install maptplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_distributions(similarity_scores):\n",
    "    cosine_similarities = [score['cosine_similarity'] for score in similarity_scores]\n",
    "    euclidean_distances = [score['euclidean_distance'] for score in similarity_scores]\n",
    "\n",
    "    # Plot Cosine Similarity Distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(cosine_similarities, bins=30, color='skyblue', edgecolor='black')\n",
    "    plt.title(\"Cosine Similarity Distribution\")\n",
    "    plt.xlabel(\"Cosine Similarity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Euclidean Distance Distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(euclidean_distances, bins=30, color='salmon', edgecolor='black')\n",
    "    plt.title(\"Euclidean Distance Distribution\")\n",
    "    plt.xlabel(\"Euclidean Distance\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the distributions\n",
    "plot_distributions(similarity_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature pairs selected for augmentation: 7506\n"
     ]
    }
   ],
   "source": [
    "def select_for_augmentation(similarity_scores, cos_threshold=0.7, euc_threshold=6.0):\n",
    "    \"\"\"\n",
    "    Select features for augmentation based on thresholds.\n",
    "    \"\"\"\n",
    "    to_augment = []\n",
    "    for score in similarity_scores:\n",
    "        if score['cosine_similarity'] < cos_threshold or score['euclidean_distance'] > euc_threshold:\n",
    "            to_augment.append((score['file1'], score['file2']))\n",
    "    return to_augment\n",
    "\n",
    "to_augment_pairs = select_for_augmentation(similarity_scores)\n",
    "print(f\"Number of feature pairs selected for augmentation: {len(to_augment_pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_32540\\352608877.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented features saved to E:\\MIL\\CODE\\augmented_features\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def augment_features(files, output_dir, noise_level=0.01):\n",
    "    \"\"\"\n",
    "    Augment features by adding Gaussian noise to individual feature files.\n",
    "\n",
    "    Args:\n",
    "        files (list): List of feature file paths to augment.\n",
    "        output_dir (str): Directory to save augmented features.\n",
    "        noise_level (float): Standard deviation of Gaussian noise.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            # Load features\n",
    "            data = torch.load(file)\n",
    "            features = data.get(\"features\")\n",
    "            if features is None:\n",
    "                print(f\"File {file} does not contain 'features'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Generate augmented features\n",
    "            aug_features = features + noise_level * torch.randn_like(features)\n",
    "\n",
    "            # Save augmented features\n",
    "            base_name = os.path.basename(file).replace(\".pt\", \"_aug.pt\")\n",
    "            torch.save({\"features\": aug_features}, os.path.join(output_dir, base_name))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "    print(f\"Augmented features saved to {output_dir}\")\n",
    "\n",
    "# Example Usage\n",
    "normal_feature_dir = r\"E:\\MIL\\CODE\\normal_features\"\n",
    "if os.path.exists(normal_feature_dir):\n",
    "    normal_files = [os.path.join(normal_feature_dir, f) for f in os.listdir(normal_feature_dir) if f.endswith(\".pt\")]\n",
    "    augment_output_dir = r\"E:\\MIL\\CODE\\augmented_features\"\n",
    "    augment_features(normal_files, augment_output_dir)\n",
    "else:\n",
    "    print(f\"Directory {normal_feature_dir} does not exist. Please check the path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating features:   0%|          | 0/200 [00:00<?, ?it/s]C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_32540\\2942537418.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  features = torch.load(file)[\"features\"]\n",
      "Aggregating features: 100%|██████████| 200/200 [00:00<00:00, 1276.06it/s]\n",
      "Calculating similarities: 100%|██████████| 200/200 [00:01<00:00, 160.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores saved to e:\\MIL\\Code\\similarity_scores.txt\n",
      "Similarity scores and mean values saved to e:\\MIL\\Code\\similarity_scores.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def aggregate_features(feature_tensor, method=\"mean\"):\n",
    "    \"\"\"\n",
    "    Aggregates features across segments.\n",
    "\n",
    "    Args:\n",
    "        feature_tensor (torch.Tensor): Input feature tensor of shape [num_segments, feature_dim].\n",
    "        method (str): Aggregation method ('mean' or 'max').\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Aggregated feature tensor of shape [feature_dim].\n",
    "    \"\"\"\n",
    "    if method == \"mean\":\n",
    "        return torch.mean(feature_tensor, dim=0)  # Mean pooling\n",
    "    elif method == \"max\":\n",
    "        return torch.max(feature_tensor, dim=0).values  # Max pooling\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported aggregation method. Use 'mean' or 'max'.\")\n",
    "\n",
    "def calculate_similarity(feat1, feat2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity and Euclidean distance between two feature tensors.\n",
    "\n",
    "    Args:\n",
    "        feat1 (torch.Tensor): First feature tensor of shape [feature_dim].\n",
    "        feat2 (torch.Tensor): Second feature tensor of shape [feature_dim].\n",
    "\n",
    "    Returns:\n",
    "        tuple: Cosine similarity and Euclidean distance.\n",
    "    \"\"\"\n",
    "    # Cosine Similarity\n",
    "    cosine_similarity = F.cosine_similarity(feat1, feat2, dim=0).item()\n",
    "\n",
    "    # Euclidean Distance\n",
    "    euclidean_distance = torch.norm(feat1 - feat2).item()\n",
    "\n",
    "    return cosine_similarity, euclidean_distance\n",
    "\n",
    "def compute_similarity_scores(directory, method=\"mean\"):\n",
    "    \"\"\"\n",
    "    Compute similarity scores for all pairs of feature files in a directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing feature files.\n",
    "        method (str): Aggregation method ('mean' or 'max').\n",
    "\n",
    "    Returns:\n",
    "        list: A list of similarity scores (cosine similarity and Euclidean distance).\n",
    "    \"\"\"\n",
    "    feature_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".pt\")]\n",
    "    aggregated_features = {}\n",
    "\n",
    "    # Aggregate features for all files\n",
    "    for file in tqdm(feature_files, desc=\"Aggregating features\"):\n",
    "        features = torch.load(file)[\"features\"]\n",
    "        aggregated_features[file] = aggregate_features(features, method=method)\n",
    "\n",
    "    # Compute similarity scores\n",
    "    similarity_scores = []\n",
    "    for i, file1 in enumerate(tqdm(feature_files, desc=\"Calculating similarities\")):\n",
    "        for file2 in feature_files[i+1:]:\n",
    "            feat1 = aggregated_features[file1]\n",
    "            feat2 = aggregated_features[file2]\n",
    "            cos_sim, euc_dist = calculate_similarity(feat1, feat2)\n",
    "            similarity_scores.append({\n",
    "                \"file1\": file1,\n",
    "                \"file2\": file2,\n",
    "                \"cosine_similarity\": cos_sim,\n",
    "                \"euclidean_distance\": euc_dist\n",
    "            })\n",
    "\n",
    "    return similarity_scores\n",
    "\n",
    "# Directory containing normal features\n",
    "normal_feature_dir = r\"E:\\MIL\\Code\\augmented_features\"\n",
    "\n",
    "# Compute similarity scores\n",
    "similarity_scores = compute_similarity_scores(normal_feature_dir, method=\"mean\")\n",
    "\n",
    "# calculate mean score\n",
    "def calculate_mean_scores(similarity_scores):\n",
    "    \"\"\"\n",
    "    Calculate the mean cosine similarity and Euclidean distance from similarity scores.\n",
    "\n",
    "    Args:\n",
    "        similarity_scores (list): List of dictionaries containing similarity metrics.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Mean cosine similarity and mean Euclidean distance.\n",
    "    \"\"\"\n",
    "    total_cosine_similarity = sum(score[\"cosine_similarity\"] for score in similarity_scores)\n",
    "    total_euclidean_distance = sum(score[\"euclidean_distance\"] for score in similarity_scores)\n",
    "    num_scores = len(similarity_scores)\n",
    "\n",
    "    mean_cosine_similarity = total_cosine_similarity / num_scores\n",
    "    mean_euclidean_distance = total_euclidean_distance / num_scores\n",
    "\n",
    "    return mean_cosine_similarity, mean_euclidean_distance\n",
    "\n",
    "# Save results to a file\n",
    "mean_cosine_similarity, mean_euclidean_distance = calculate_mean_scores(similarity_scores)\n",
    "\n",
    "# Save results to a file\n",
    "# Ensure output directory is valid and writable\n",
    "output_dir = os.getcwd()  # Use the current working directory\n",
    "output_file = os.path.join(output_dir, \"similarity_scores.txt\")\n",
    "\n",
    "try:\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for score in similarity_scores:\n",
    "            f.write(f\"Cosine Similarity: {score['cosine_similarity']:.4f}, Euclidean Distance: {score['euclidean_distance']:.4f}\\n\")\n",
    "    print(f\"Similarity scores saved to {output_file}\")\n",
    "except OSError as e:\n",
    "    print(f\"Error saving similarity scores: {e}\")\n",
    "\n",
    "# Append mean scores to the file\n",
    "with open(output_file, \"a\") as f:\n",
    "    f.write(f\"\\nMean Cosine Similarity: {mean_cosine_similarity:.4f}\\n\")\n",
    "    f.write(f\"Mean Euclidean Distance: {mean_euclidean_distance:.4f}\\n\")\n",
    "\n",
    "print(f\"Similarity scores and mean values saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7460603922934987"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.739580016783134"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_32540\\1815697533.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  features = torch.load(file)[\"features\"]  # Load features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max segments in train normal: 675 (File: E:\\MIL\\Code\\split\\train\\normal\\Normal_Videos_924_x264_features_aug.pt)\n",
      "Max segments in train anomaly: 887 (File: E:\\MIL\\Code\\split\\train\\anomalous\\Explosion046_x264_features.pt)\n",
      "Max segments in val normal: 675 (File: E:\\MIL\\Code\\split\\val\\normal\\Normal_Videos_935_x264_features_aug.pt)\n",
      "Max segments in val anomaly: 281 (File: E:\\MIL\\Code\\split\\val\\anomalous\\Burglary061_x264_features.pt)\n",
      "Max segments in test normal: 242 (File: E:\\MIL\\Code\\split\\test\\normal\\Normal_Videos_925_x264_features_aug.pt)\n",
      "Max segments in test anomaly: 271 (File: E:\\MIL\\Code\\split\\test\\anomalous\\Arrest030_x264_features.pt)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def find_max_segments(data_dir):\n",
    "    \"\"\"\n",
    "    Finds the maximum number of segments in the feature tensors for the given directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Path to the directory containing feature files.\n",
    "\n",
    "    Returns:\n",
    "        int: Maximum number of segments.\n",
    "        str: File name of the tensor with the max segments.\n",
    "    \"\"\"\n",
    "    max_segments = 0\n",
    "    max_file = None\n",
    "\n",
    "    feature_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".pt\")]\n",
    "\n",
    "    for file in feature_files:\n",
    "        features = torch.load(file)[\"features\"]  # Load features\n",
    "        num_segments = features.shape[0]  # Number of segments is the first dimension (B)\n",
    "        if num_segments > max_segments:\n",
    "            max_segments = num_segments\n",
    "            max_file = file\n",
    "\n",
    "    return max_segments, max_file\n",
    "\n",
    "# Directories for splits\n",
    "splits = {\n",
    "    \"train\": {\"normal\": r\"E:\\MIL\\Code\\split\\train\\normal\", \"anomaly\":r\"E:\\MIL\\Code\\split\\train\\anomalous\"},\n",
    "    \"val\": {\"normal\": r\"E:\\MIL\\Code\\split\\val\\normal\", \"anomaly\": r\"E:\\MIL\\Code\\split\\val\\anomalous\"},\n",
    "    \"test\": {\"normal\": r\"E:\\MIL\\Code\\split\\test\\normal\", \"anomaly\": r\"E:\\MIL\\Code\\split\\test\\anomalous\"}\n",
    "}\n",
    "\n",
    "# Find maximum segments for each split\n",
    "for split_name, dirs in splits.items():\n",
    "    for label, dir_path in dirs.items():\n",
    "        max_segments, max_file = find_max_segments(dir_path)\n",
    "        print(f\"Max segments in {split_name} {label}: {max_segments} (File: {max_file})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([89, 2048, 1, 1, 1])\n",
      "torch.Size([38, 2048, 1, 1, 1])\n",
      "torch.Size([57, 2048, 1, 1, 1])\n",
      "torch.Size([86, 2048, 1, 1, 1])\n",
      "torch.Size([116, 2048, 1, 1, 1])\n",
      "torch.Size([198, 2048, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_32540\\2885363860.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  normal_files=[torch.load(r\"E:\\MIL\\Code\\normal_features\\Normal_Videos_003_x264_features_aug.pt\"),torch.load(r\"E:\\MIL\\Code\\normal_features\\Normal_Videos_866_x264_features.pt\"),torch.load(r\"E:\\MIL\\Code\\normal_features\\Normal_Videos_656_x264_features.pt\")]\n",
      "C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_32540\\2885363860.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  anomaly_files=[torch.load(r\"E:\\MIL\\Code\\anomaly_features\\Abuse001_x264_features.pt\"),torch.load(r\"E:\\MIL\\Code\\anomaly_features\\Abuse003_x264_features.pt\"),torch.load(r\"E:\\MIL\\Code\\anomaly_features\\Fighting041_x264_features.pt\")]\n"
     ]
    }
   ],
   "source": [
    "normal_files=[torch.load(r\"E:\\MIL\\Code\\normal_features\\Normal_Videos_003_x264_features_aug.pt\"),torch.load(r\"E:\\MIL\\Code\\normal_features\\Normal_Videos_866_x264_features.pt\"),torch.load(r\"E:\\MIL\\Code\\normal_features\\Normal_Videos_656_x264_features.pt\")]\n",
    "anomaly_files=[torch.load(r\"E:\\MIL\\Code\\anomaly_features\\Abuse001_x264_features.pt\"),torch.load(r\"E:\\MIL\\Code\\anomaly_features\\Abuse003_x264_features.pt\"),torch.load(r\"E:\\MIL\\Code\\anomaly_features\\Fighting041_x264_features.pt\")]\n",
    "for f in normal_files:\n",
    "    print(f['features'].shape)\n",
    "for f in anomaly_files:\n",
    "    print(f['features'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikra\\AppData\\Local\\Temp\\ipykernel_32540\\2194874579.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(r\"E:\\MIL\\Code\\normal_features\\Normal_Videos124_x264_features.pt\")['features'].shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([44, 2048, 1, 1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.load(r\"E:\\MIL\\Code\\normal_features\\Normal_Videos124_x264_features.pt\")['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlapping files found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "# Function to compute the hash of a file\n",
    "def compute_file_hash(filepath):\n",
    "    hash_func = hashlib.sha256()  # Use SHA256 for robust hashing\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        while chunk := f.read(8192):  # Read file in chunks\n",
    "            hash_func.update(chunk)\n",
    "    return hash_func.hexdigest()\n",
    "\n",
    "# Function to get all file hashes in a directory\n",
    "def get_file_hashes(directory):\n",
    "    file_hashes = {}\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root, file)\n",
    "            file_hashes[filepath] = compute_file_hash(filepath)\n",
    "    return file_hashes\n",
    "\n",
    "# Directories to check\n",
    "directories = {\n",
    "    \"train_normal\": \"split/train/normal\",\n",
    "    \"train_anomalous\": \"split/train/anomalous\",\n",
    "    \"val_normal\": \"split/val/normal\",\n",
    "    \"val_anomalous\": \"split/val/anomalous\",\n",
    "    \"test_normal\": \"split/test/normal\",\n",
    "    \"test_anomalous\": \"split/test/anomalous\",\n",
    "}\n",
    "\n",
    "# Collect all hashes\n",
    "hashes = {name: get_file_hashes(path) for name, path in directories.items()}\n",
    "\n",
    "# Compare hashes between directories\n",
    "overlap_found = False\n",
    "for dir1_name, dir1_hashes in hashes.items():\n",
    "    for dir2_name, dir2_hashes in hashes.items():\n",
    "        if dir1_name != dir2_name:  # Don't compare the same directory\n",
    "            common_hashes = set(dir1_hashes.values()) & set(dir2_hashes.values())\n",
    "            if common_hashes:\n",
    "                print(f\"Overlap found between {dir1_name} and {dir2_name}:\")\n",
    "                for hash_value in common_hashes:\n",
    "                    file1 = [k for k, v in dir1_hashes.items() if v == hash_value]\n",
    "                    file2 = [k for k, v in dir2_hashes.items() if v == hash_value]\n",
    "                    print(f\"  {file1[0]} == {file2[0]}\")\n",
    "                overlap_found = True\n",
    "\n",
    "if not overlap_found:\n",
    "    print(\"No overlapping files found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pytube\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "Installing collected packages: pytube\n",
      "Successfully installed pytube-15.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall yt-dlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade wheel setuptools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 433] A device which does not exist was specified: 'yt_dlp_plugins'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myt_dlp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/MIL/Dataset/youtube\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m link \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/watch?v=owO2-pjxOqs\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\yt_dlp\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcookies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SUPPORTED_BROWSERS, SUPPORTED_KEYRINGS, CookieLoadError\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_external_downloader\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextractor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_extractor_classes\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextractor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madobepass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSO_INFO\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\yt_dlp\\downloader\\__init__.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileDownloader\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DashSegmentsFD\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FFmpegFD, get_external_downloader\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mf4m\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F4mFD\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfc2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FC2LiveFD\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\yt_dlp\\downloader\\external.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfragment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FragmentFD\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Request\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpostprocessor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffmpeg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EXT_TO_OUT_FORMATS, FFmpegPostProcessor\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     Popen,\n\u001b[0;32m     17\u001b[0m     RetryManager,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     traverse_obj,\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFeatures\u001b[39;00m(enum\u001b[38;5;241m.\u001b[39mEnum):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\yt_dlp\\postprocessor\\__init__.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxattrpp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XAttrMetadataPP\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_plugins\n\u001b[1;32m---> 38\u001b[0m _PLUGIN_CLASSES \u001b[38;5;241m=\u001b[39m \u001b[43mload_plugins\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpostprocessor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_postprocessor\u001b[39m(key):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPP\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\yt_dlp\\plugins.py:151\u001b[0m, in \u001b[0;36mload_plugins\u001b[1;34m(name, suffix)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYTDLP_NO_PLUGINS\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m classes\n\u001b[1;32m--> 151\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\yt_dlp\\plugins.py:133\u001b[0m, in \u001b[0;36miter_modules\u001b[1;34m(subpackage)\u001b[0m\n\u001b[0;32m    131\u001b[0m fullname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPACKAGE_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubpackage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39msuppress(\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m):\n\u001b[1;32m--> 133\u001b[0m     pkg \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m pkgutil\u001b[38;5;241m.\u001b[39miter_modules(path\u001b[38;5;241m=\u001b[39mpkg\u001b[38;5;241m.\u001b[39m__path__, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfullname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1322\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1262\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\yt_dlp\\plugins.py:110\u001b[0m, in \u001b[0;36mPluginFinder.find_spec\u001b[1;34m(self, fullname, path, target)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fullname \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpackages:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m search_locations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m search_locations:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\yt_dlp\\plugins.py:98\u001b[0m, in \u001b[0;36mPluginFinder.search_locations\u001b[1;34m(self, fullname)\u001b[0m\n\u001b[0;32m     96\u001b[0m candidate \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m/\u001b[39m parts\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcandidate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m candidate\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.egg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.whl\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m path\u001b[38;5;241m.\u001b[39mis_file():\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\pathlib.py:875\u001b[0m, in \u001b[0;36mPath.is_dir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;124;03mWhether this path is a directory.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m S_ISDIR(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mst_mode)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _ignore_error(e):\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\pathlib.py:840\u001b[0m, in \u001b[0;36mPath.stat\u001b[1;34m(self, follow_symlinks)\u001b[0m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, follow_symlinks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    836\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;124;03m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;124;03m    os.stat() does.\u001b[39;00m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 433] A device which does not exist was specified: 'yt_dlp_plugins'"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "\n",
    "save_path = 'E:/MIL/Dataset/youtube'\n",
    "link = 'https://www.youtube.com/watch?v=owO2-pjxOqs'\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestvideo+bestaudio/best',\n",
    "    'outtmpl': f'{save_path}/%(title)s.%(ext)s',\n",
    "}\n",
    "\n",
    "try:\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([link])\n",
    "    print('Video downloaded successfully')\n",
    "except Exception as e:\n",
    "    print(f'Error during download: {e}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
